# Dimensional Logic for LLM Output Selection

This repository contains a **proof-of-concept implementation** of applying **Dimensional Logic (Ïƒâ‚‚, Î¼â‚ƒ, Îºâ‚„)** to large language model (LLM) outputs.  
The goal is to improve **reflexivity** (reasoning about reasoning) and **context coherence** when selecting between candidate answers generated by an LLM.

---

## ğŸ” Background

Classical logic evaluates statements in binary terms (true/false).  
**Dimensional Logic** extends this by introducing additional operators:

- **Ïƒâ‚‚ (Systematic Derivation)** â€“ ensures structural consistency in reasoning  
- **Î¼â‚ƒ (Reflexivity)** â€“ models recursive awareness of reasoning steps  
- **Îºâ‚„ (Context Coherence)** â€“ evaluates how well reasoning fits into a broader context  

This framework allows us to score and re-rank LLM responses not only by surface plausibility but also by **epistemic depth**.

---

## ğŸ“‚ Repository Contents

- `dimensional_llm_selector_en.py` â†’ Python implementation of dimensional scoring and selection  
- (optional) Example CSV / heatmap â†’ demo results from a toy experiment  

---

## ğŸš€ Usage

1. Clone this repo:
   ```bash
   git clone https://github.com/yourusername/dimensional-logic-llm-selector.git
   cd dimensional-logic-llm-selector
   ```

2. Run the script with sample outputs:
   ```python
   from dimensional_llm_selector_en import dimensional_score, select_best_response

   outputs = [
       "The capital of France is Paris.",
       "The capital of France is Lyon.",
       "The capital of France is Madrid."
   ]

   context = "Geography, European capitals"

   best = select_best_response(outputs, context)
   print("Best response:", best)
   ```

3. Example output:
   ```
   Best response: The capital of France is Paris.
   ```

---

## ğŸ“Š How It Works

Each LLM response is scored as:

```
Score = Î± Â· Î¼â‚ƒ(response, others) + Î² Â· Îºâ‚„(response, context)
```

- **Î¼â‚ƒ**: Reflexive alignment â€“ does the answer make sense relative to others?  
- **Îºâ‚„**: Contextual coherence â€“ does the answer fit into the given context?  
- **Î±, Î²**: Tunable weights to balance reflexivity and coherence.  

If the **dimensional score** passes a threshold, the response is preferred over naive likelihood-based ranking.

---

## ğŸ§  Applications

- More reliable **multi-agent reasoning**  
- Reducing **hallucinations** in LLMs by epistemic filtering  
- Extending **game theory** and **decision theory** with reflexive/contextual dimensions  
- Foundations for **epistemic-aware AI systems**

---

## ğŸ“œ License

MIT License â€“ free to use, modify, and share.  

---

## ğŸ“– References

- Stegemann, W. (2025). *Dimensional Mathematics: An Axiomatic Extension of Epistemic Relativity. https://doi.org/10.5281/zenodo.16911643
